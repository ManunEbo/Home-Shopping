{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc2e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Loading environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# connecting to MySQL database using URL connection string\n",
    "sqlUrl = sqlalchemy.engine.URL.create(\n",
    "    drivername = os.getenv('drivername'),\n",
    "    username = os.getenv('username'),\n",
    "    password = os.getenv('password'),\n",
    "    host = os.getenv('host'),\n",
    "    port = os.getenv('port'),\n",
    "    database = os.getenv('database')\n",
    ")\n",
    "\n",
    "engine = sqlalchemy.create_engine(sqlUrl)\n",
    "\n",
    "Venue_id_g = 26\n",
    "Total_Nbr_of_Items_g = 11\n",
    "Total_Price_g = 15.44\n",
    "Receipt_Date_g = pd.to_datetime('2022-10-04', format=\"%Y-%m-%d\")\n",
    "Receipt_Time_g = datetime.strptime('19:10:01','%H:%M:%S').time()\n",
    "\n",
    "\n",
    "Payment_Type_g = 'Card'\n",
    "Card_Source_g = 'Contactless'\n",
    "\n",
    "Item_name_g = ['Whole chicken','Garlic pouch','Chopped tomatoes',\n",
    "               'Chopped tomatoes','Chopped tomatoes','Lemons',\n",
    "               'Limes','Vimto','Red onions','Peppers mixed','Colgate']\n",
    "Item_Price_g = [4.98,2.79,0.32,0.32,0.32,0.79,0.79,2.50,0.67,0.97,0.99]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f323ac5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(Venue_id_g,Total_Nbr_of_Items_g,Total_Price_g,\n",
    "            Receipt_Date_g,Receipt_Time_g,Payment_Type_g,\n",
    "            Card_Source_g,Item_name_g,Item_Price_g\n",
    "           ):\n",
    "    sql_str = \"\"\"select *,yearweek(Receipt_date) as week_of_year\n",
    "                from hs.receipt\n",
    "                where yearweek(Receipt_date) = yearweek(curdate())\n",
    "                order by Receipt_id desc;\"\"\"\n",
    "    \n",
    "    Receipt = pd.read_sql_query(sql_str,engine)\n",
    "    Receipt.drop(['Receipt_Nbr','Trans_number','Barcode','Date_Added'], axis=1, inplace=True)\n",
    "    \n",
    "    Receipt['Receipt_Time'] = Receipt['Receipt_Time'].apply(lambda x: \n",
    "                                              datetime.strptime(str(x).split(' ')[2],\n",
    "                                                                '%H:%M:%S'\n",
    "                                                               ).time())\n",
    "    \n",
    "    receipt_ids = tuple(Receipt.Receipt_id.values.tolist())    \n",
    "    new_receipt_id = max(receipt_ids) + 1    \n",
    "    Receipt_id_g = new_receipt_id\n",
    "    \n",
    "    week_of_year_g = max(tuple(Receipt.week_of_year.values.tolist()))\n",
    "    \n",
    "    # add new receipt\n",
    "    new_row_r = {'Receipt_id':Receipt_id_g,\n",
    "           'Venue_id': Venue_id_g,\n",
    "           'Total_Nbr_of_Items': Total_Nbr_of_Items_g,\n",
    "           'Total_Price': Total_Price_g,\n",
    "           'Receipt_Date': Receipt_Date_g.date(),\n",
    "           'Receipt_Time': Receipt_Time_g,\n",
    "           'week_of_year': week_of_year_g\n",
    "          }\n",
    "    \n",
    "    new_row_r = pd.DataFrame(new_row_r, columns=Receipt.columns, index=[0])\n",
    "    Receipt = pd.concat([Receipt,new_row_r], ignore_index=True)\n",
    "    \n",
    "    sql_str0 = \"\"\"select * from hs.payment\n",
    "                where Receipt_id in {}\n",
    "                order by Payment_id desc;\"\"\".format(receipt_ids)\n",
    "    \n",
    "    Payment = pd.read_sql_query(sql_str0,engine)\n",
    "    Payment.drop(['Card_Nbr','Aid','Auth_Code','Date_Added'],axis=1, inplace=True)\n",
    "    \n",
    "    Payment_id_g = max(tuple(Payment.Payment_id.values.tolist())) + 1\n",
    "    \n",
    "    new_row_p = {'Payment_id': Payment_id_g, \n",
    "           'Receipt_id':Receipt_id_g,\n",
    "           'Payment_Type': Payment_Type_g,\n",
    "           'Card_Source': Card_Source_g\n",
    "          }\n",
    "    \n",
    "    new_row_p = pd.DataFrame(new_row_p, columns=Payment.columns, index=[0])\n",
    "    \n",
    "    Payment = pd.concat([Payment,new_row_p], ignore_index=True)\n",
    "    \n",
    "    sql_str1 = \"\"\"select * from hs.item\n",
    "                where Receipt_id in {}\n",
    "                order by Item_id desc;\"\"\".format(receipt_ids)\n",
    "    \n",
    "    Item = pd.read_sql_query(sql_str1,engine)\n",
    "    \n",
    "    Item.drop(['Venue_Item_code','Venue_id','Date_Added'], axis=1, inplace=True)\n",
    "    \n",
    "    Item_id_g = max(tuple(Item.Item_id.values.tolist())) + 1\n",
    "    \n",
    "    for i in range(len(Item_name_g)):\n",
    "        new_row_i = {'Item_id': Item_id_g,\n",
    "                     'Receipt_id': Receipt_id_g,\n",
    "                     'Item_name':Item_name_g[i],\n",
    "                     'Item_Price':Item_Price_g[i]\n",
    "                    }\n",
    "        new_row_i = pd.DataFrame(new_row_i, columns=Item.columns, index=[0])\n",
    "        Item = pd.concat([Item,new_row_i], ignore_index=True)\n",
    "        \n",
    "    # Excluding refunds i.e. negative Total_Price\n",
    "    Receipt = Receipt[Receipt.Total_Price > 0]\n",
    "    \n",
    "    # Deriving the difference in days between shopping trips\n",
    "\n",
    "    # sorting the data in ascending date order\n",
    "    Receipt.sort_values('Receipt_Date',ascending=True, inplace=True)\n",
    "\n",
    "    # calculating the date difference using the shift() method to get the lag -1 value\n",
    "    # and retrieving the numeric part of date difference\n",
    "    Receipt['Date_diff'] = (Receipt.Receipt_Date - Receipt.Receipt_Date.shift()).dt.days\n",
    "\n",
    "    # Deriving the weekdate\n",
    "    week = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "    # [week[x.weekday()] for x in Receipt.Receipt_Date]\n",
    "    Receipt['Week_day'] = Receipt.Receipt_Date.apply(lambda x: week[x.weekday()])\n",
    "\n",
    "    # Retrieving only the numeric version of weekday()\n",
    "    # adding 1 to remove the 0 for the first day\n",
    "    Receipt['Week_day_numeric'] = Receipt.Receipt_Date.apply(lambda x: x.weekday()) + 1\n",
    "    \n",
    "    # Calculate the number of trips per week\n",
    "    Receipt['Nbr_trips_per_wk'] = Receipt.groupby(['week_of_year'])['Receipt_id'].transform('count')\n",
    "\n",
    "    # Calculate number of items bought per week\n",
    "    Receipt['Nbr_items_per_wk'] = Receipt.groupby(['week_of_year'])['Total_Nbr_of_Items'].transform('sum')\n",
    "    # Calculating receipt Total_Nbr_of_Items as a percentage of the weeks Total_Nbr_of_Items \n",
    "    Receipt['Nbr_items_wk_perc'] = Receipt.Total_Nbr_of_Items / Receipt.Nbr_items_per_wk\n",
    "\n",
    "    # Calculate expenditure per week\n",
    "    Receipt['Expenditure_per_wk'] = Receipt.groupby(['week_of_year'])['Total_Price'].transform('sum')\n",
    "    # Calculating receipt Total_Price as a percentage of the weeks expenditure\n",
    "    Receipt['Total_Exp_wk_perc'] = Receipt.Total_Price / Receipt.Expenditure_per_wk\n",
    "    \n",
    "    # extract the time of day as morning, afternoon, evening etc\n",
    "    Receipt['hour'] = Receipt['Receipt_Time'].apply(lambda x: x.hour)\n",
    "\n",
    "    bins_= [0,7,11,17,20,23]\n",
    "    lbl = ['Early','Morning','Afternoon','Evening','Late_night']\n",
    "\n",
    "    Receipt['Part_of_day'] = pd.cut(Receipt['hour'],bins=bins_, labels=lbl, include_lowest=True)\n",
    "    \n",
    "    # merging Payment to Receipt for the analysis\n",
    "    Receipt_Payment = pd.merge(Receipt, \n",
    "                               Payment[['Receipt_id','Payment_Type','Card_Source']], \n",
    "                               on='Receipt_id', how='left')\n",
    "    \n",
    "    raw0 = pd.merge(Receipt_Payment,\n",
    "                     Item[['Receipt_id','Item_id','Item_name','Item_Price']], \n",
    "                     on='Receipt_id', \n",
    "                     how='left' )\n",
    "    \n",
    "    # Grouping items and creating new features\n",
    "    \n",
    "    # breads\n",
    "    nots = ['garlic','Ham','Garlic','ham']\n",
    "    ins = ['Bread','bloomer','bread','Bloomer']\n",
    "\n",
    "    raw0['Bread'] = raw0.Item_name.apply(lambda sentence: 1 if any(word in sentence for word in ins) \n",
    "                                and not any(word in sentence for word in nots) else 0)\n",
    "    \n",
    "    # Cooked meats indicator\n",
    "    not_cook = ['glass','shampoo','water','conditioner','champagne']\n",
    "    cooked_meats = ['chicken pasty Slices twin pack','steak and kidney pasty',\n",
    "                    'chicken cooked','cooked chicken','roast chicken thighs',\n",
    "                    'mackerel','Salmon','pork pies classic','ham',\n",
    "                    'sardines','sausages cocktail','spicy chorizo sausages',\n",
    "                    'sausages rolls','sausage rolls','salami','meatballs']\n",
    "\n",
    "    raw0['Cooked_meats'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                any(word.lower() in sentence.lower() \n",
    "                                                    for word in cooked_meats) \n",
    "                                                and not any(word.lower() in sentence.lower() \n",
    "                                                            for word in not_cook) \n",
    "                                                else 0)\n",
    "    \n",
    "    # Raw meats indicator\n",
    "    not_raw = ['pasty','cooked','roast','seasoning',\n",
    "               'southern','fried','meal','piece',\n",
    "               'box','bake','szechuan','pies',\n",
    "               'mushroom','pie','salami','rolls','cocktails',\n",
    "               'chips','chorizo']\n",
    "    raw_meats = ['bacon','chicken','lamb','gammon','sausages',\n",
    "                 'sausage','pork','fish','beef','eggs']\n",
    "\n",
    "    raw0['Raw_meats'] = raw0.Item_name.apply(lambda sentence: 1 if any(word.lower() in sentence.lower() for word in raw_meats) \n",
    "                                and not any(word.lower() in sentence.lower() for word in not_raw) else 0)\n",
    "    \n",
    "    # Creating eating out indicator using the restaurants and fastfoods Venue id\n",
    "    eating_out = [11,20,25,31,34,35,40,41,42,48]\n",
    "    raw0['Eating_out'] = raw0.apply(lambda x: 1 if x['Venue_id'] in eating_out or \n",
    "                                             x['Item_name'] in ['Food @ space centre',\n",
    "                                                             'Drinks @ space centre'] \n",
    "                                             else 0,axis=1)\n",
    "\n",
    "    # Creating snack indicator\n",
    "    not_snack = ['diesel','james']\n",
    "    snacks = ['snickers','digestive','digestives',\n",
    "              'chocolate','yogurt','cake','cakes',\n",
    "              'snack','nuts','donuts','doughnut',\n",
    "              'mikati','fudge','maltesers','twix','marmalade',\n",
    "              'jam','custard']\n",
    "\n",
    "    raw0['Snacks'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                          any(word.lower() in sentence.lower() for word in snacks)\n",
    "                                          and not \n",
    "                                          any(word.lower() in sentence.lower() for word in not_snack)\n",
    "                                         else 0)\n",
    "    \n",
    "    # Creating drinks indicator variable\n",
    "    # Note: this includes alcoholic and non alcoholic drinks\n",
    "\n",
    "    not_drink = ['diesel','glass','socks','fan','heater',\n",
    "                 'beef','source','ironing','plaster','ham','lockets']\n",
    "\n",
    "    drinks = ['juice','vimto','ribena','squash','tropical','liquer',\n",
    "              'dr pepper','coke','alcohol','beer','rubicon','courvoisier'\n",
    "              'wine','irish','port','rum','original','smoothies','water',\n",
    "              'honey','cordial','whiskey']\n",
    "\n",
    "    raw0['Drinks'] = raw0.Item_name.apply(lambda sentence: 1 if any(word.lower() in sentence.lower()\n",
    "                                                                    for word in drinks) \n",
    "                                          and not any(word.lower() in sentence.lower() \n",
    "                                                      for word in not_drink)\n",
    "                                         else 0)\n",
    "    \n",
    "    # Creating a vegetables indicator\n",
    "    not_veg = ['seed','bread','fried','black','dr','lisbon']\n",
    "    vegetables = ['cabbage','carrots','parsnip','greens','garlic','ginger',\n",
    "                  'tomatoes','onions','chillies','ngai ngai','leaf',\n",
    "                  'leaves','mushrooms','spinach','coriander','parsley',\n",
    "                  'broccoli','pumpkin','peas','peppers','cucumber','leeks',\n",
    "                 'brussel sprouts','mint','asparagus','beans']\n",
    "\n",
    "    raw0['Vegetables'] = raw0.Item_name.apply(lambda sentence: \n",
    "                                              1 if any(word.lower() in sentence.lower() \n",
    "                                                       for word in vegetables)\n",
    "                                             and not any(word.lower() in sentence.lower() \n",
    "                                                         for word in not_veg)\n",
    "                                             else 0)\n",
    "    \n",
    "    # Creating a fruits indicator\n",
    "    not_fruit = ['juice','rubicon','original','smoothies','yogurt','cordial',\n",
    "                 'ribena','squash','volvic','water','lockets','bucket']\n",
    "    fruit = ['olives','apples','mango','grape','grapes','bananas',\n",
    "              'lime','lemon','strawberries','oranges']\n",
    "\n",
    "    raw0['Fruit'] = raw0.Item_name.apply(lambda sentence: 1 if any(word.lower() in sentence.lower() \n",
    "                                                                   for word in fruit) \n",
    "                                         and not any(word.lower() in sentence.lower() \n",
    "                                                     for word in not_fruit)\n",
    "                                        else 0)\n",
    "    \n",
    "    # Creating an indicator for cooking base\n",
    "    not_base = ['fried']\n",
    "    cooking_base = ['pasta','spaghetti','rice','flour','potatoe','potatoes','potato']\n",
    "\n",
    "    raw0['Cooking_base'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                any(word.lower() in sentence.lower() \n",
    "                                                    for word in cooking_base) \n",
    "                                                and not any(word.lower() in sentence.lower() \n",
    "                                                            for word in not_base) \n",
    "                                                else 0)\n",
    "    \n",
    "    # Creating an indicator for Dairy produce\n",
    "    dairy_produce = ['cheese','brilliantly','butter','butterlicious','spread','margarine']\n",
    "    raw0['Dairy_produce'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                 any(word.lower() in sentence.lower() \n",
    "                                                     for word in dairy_produce) \n",
    "                                                 else 0)\n",
    "    \n",
    "    # Creating an indicator for seasoning\n",
    "    seasoning = ['black pepper','salt','seasoning','spice','cinnamon','paprika']\n",
    "\n",
    "    raw0['Seasoning'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                             any(word.lower() in sentence.lower() \n",
    "                                                 for word in seasoning) \n",
    "                                             else 0 )\n",
    "    \n",
    "    # creating an indicator for breakfast food\n",
    "    breakfast = ['granola','muesli','sultanas']\n",
    "\n",
    "    raw0['Breakfast'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                             any(word.lower() in sentence.lower() \n",
    "                                                 for word in breakfast) \n",
    "                                             else 0 )\n",
    "    \n",
    "    # Creating an indicator for transport\n",
    "    transport = ['unleaded','diesel','return ticket']\n",
    "    raw0['Transport'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                             any(word.lower() in sentence.lower() \n",
    "                                                 for word in transport)\n",
    "                                             else 0)\n",
    "    \n",
    "    # Creating an indicator for diy\n",
    "    not_diy = ['sony']\n",
    "    diy = ['fifty box 44l black','soil scoop','garden glove','compost','carrot amsterdam',\n",
    "           'cabbage copenhagen','parsnip gladiator','Spring onion white lisbon seed','bucket',\n",
    "           'onion white ailsa craig seed','dahlia assorted bright seed','gorilla',\n",
    "           'kaze box','galvanised garden wheelbarrow','magnusson 500mm steel ruler',\n",
    "           'tape measure','timber','bosch 34 piece drill accessory','wood screw steel',\n",
    "           'bolted screws set','decking srew csk pz pk500','heavy duty rubble sacks 50l',\n",
    "           'magnusson screw driver slot 100 x','wiha slotted screw driver 150 x',\n",
    "           'general purpose plier set 3pc','mag ratchet precision Screwdriver',\n",
    "           'diall l75 decking screws 250pck','chrome plated barrel latch','wire',\n",
    "           'satin nickel barrel latch','chrome plated barrel latch',\n",
    "           'ronseal varnish outdoor clear gloss','zipper metal silver teeth',\n",
    "           'neodymium magnets']\n",
    "\n",
    "    raw0['DIY'] = raw0.Item_name.apply(lambda sentence: 1 if any(word.lower() in sentence.lower() \n",
    "                                                                 for word in diy) \n",
    "                                       and not any(word.lower() in sentence.lower() \n",
    "                                                   for word in not_diy) \n",
    "                                       else 0)\n",
    "    \n",
    "    # Creating an indicator for electronics\n",
    "    electronics = ['macallister combi drill','macallister multipendulum jigsaw 600w',\n",
    "                   'bench table saw','fan heater','voltmeter','hair clippers wahl',\n",
    "                   'silk steamer','vacuum cleaner','table saw',\n",
    "                   'rotary tool kit','reciprocating saws','air fryer oven']\n",
    "\n",
    "    raw0['Electronics'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                               any(word.lower() in sentence.lower() \n",
    "                                                   for word in electronics) \n",
    "                                               else 0)\n",
    "    \n",
    "    # creating an indicator for education\n",
    "    not_edu = ['clevo']\n",
    "    education = ['King Richard Williams','linkedin','mysql','financial','python',\n",
    "                 'bootcamp','web server','linux','apache','sas','pencils',\n",
    "                 'eraser','WHS 15cm ruler','bic pen','a4','binders']\n",
    "\n",
    "    raw0['Education'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                             any(word.lower() in sentence.lower() \n",
    "                                                 for word in education) \n",
    "                                             and not \n",
    "                                             any(word.lower() in sentence.lower() \n",
    "                                                 for word in not_edu) \n",
    "                                             else 0)\n",
    "\n",
    "    # Creating an indicator for tech and services\n",
    "    tech_and_services = ['macbook pro','flash drive','lonovo','sony','clevo','tesco','domain registration',\n",
    "                         'membership payment']\n",
    "\n",
    "    raw0['Tech_and_services'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                     any(word.lower() in sentence.lower() \n",
    "                                                         for word in tech_and_services) \n",
    "                                                     else 0)\n",
    "\n",
    "    # Creating an indicator for cosmetics and self care\n",
    "\n",
    "    not_cosmetic = ['sony']\n",
    "    cosmetics_and_selfcare = ['shampoo','shower','tooth','colgate','wisdom','nivea',\n",
    "                              'razor','body','blades','aqueous','shave','african',\n",
    "                              'perfume','brut','roll on','Roll-on','bettina bath']\n",
    "\n",
    "    raw0['Cosmetics_and_selfcare'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                          any(word.lower() in sentence.lower() \n",
    "                                                              for word in cosmetics_and_selfcare) \n",
    "                                                          and not \n",
    "                                                          any(word.lower() in sentence.lower() \n",
    "                                                              for word in not_cosmetic) \n",
    "                                                          else 0)\n",
    "    \n",
    "    # Creating an indicator for clothes and shoes\n",
    "    clothes_and_shoes = ['lonsdale','slaz','trainers','addidas','puma','sondico','nike',\n",
    "                         'umbrella','trousers','socks','shirt','boxers','gloves','boots',\n",
    "                         'insoles']\n",
    "    raw0['Clothes_and_shoes'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                     any(word.lower() in sentence.lower() \n",
    "                                                         for word in clothes_and_shoes) \n",
    "                                                     else 0)\n",
    "\n",
    "    # creating an indicator for house and kitchen \n",
    "    not_house = ['cake']\n",
    "    house_and_kitchen = ['fairy liquid','measure jug','fitted bed sheet','glass',\n",
    "                         'turner (spatula)','rolling pin','fairy liquid','orange citrus',\n",
    "                         'turkey baster','dish drainer','extension lead','grater','power spray',\n",
    "                         'liquid','roaster and rack','kitchen roller','salad tongs',\n",
    "                         'strainer 12cm','arial pods','metal scourer','bathmat','curtain hooks',\n",
    "                         'ant killer spray','scouring pads','sponge','surf','foil','plaster',\n",
    "                         'knife sharpener','electric hand mixer','athena cotton wool','mop',\n",
    "                         'ofargo']\n",
    "\n",
    "    raw0['House_and_kitchen'] = raw0.Item_name.apply(lambda sentence: 1 if \n",
    "                                                     any(word.lower() in sentence.lower() \n",
    "                                                         for word in house_and_kitchen) \n",
    "                                                     and not \n",
    "                                                     any(word.lower() in sentence.lower() \n",
    "                                                         for word in not_house) \n",
    "                                                     else 0)\n",
    "    \n",
    "    indicator_list = ['Bread','Cooked_meats','Raw_meats','Eating_out','Snacks','Drinks',\n",
    "                  'Vegetables','Fruit','Cooking_base','Dairy_produce','Seasoning',\n",
    "                  'Breakfast','Transport','DIY','Electronics','Education',\n",
    "                  'Tech_and_services','Cosmetics_and_selfcare','Clothes_and_shoes',\n",
    "                  'House_and_kitchen']\n",
    "\n",
    "    # Looping through the indicator list to derive new features\n",
    "    for x in indicator_list:\n",
    "        # Calculate item x count by shopping trip(Receipt) and by week\n",
    "        raw0[\"{}_receipt\".format(x)] = raw0.groupby(['Receipt_id'])[x].transform('sum')\n",
    "        raw0[\"{}_wk\".format(x)] = raw0.groupby(['week_of_year'])[x].transform('sum')\n",
    "\n",
    "        # Receipt item x as a proportion of week's item x\n",
    "        raw0[\"{}_wk_perc\".format(x)] = raw0[\"{}_receipt\".format(x)] / raw0[\"{}_wk\".format(x)]\n",
    "\n",
    "        # Calculating item x expenditure by shopping trip(Receipt) and by week\n",
    "        raw0[\"{}_exp_receipt\".format(x)] = \\\n",
    "        raw0.query(\"{}==1\".format(x)).groupby(['Receipt_id',x])['Item_Price'].transform('sum')\n",
    "\n",
    "        raw0[\"{}_exp_wk\".format(x)] = \\\n",
    "        raw0.query(\"{}==1\".format(x)).groupby(['week_of_year',x])['Item_Price'].transform('sum')\n",
    "\n",
    "        # Receipt item x expenditure as a proportion of week's item x expenditure\n",
    "        raw0[\"{}_wk_exp_perc\".format(x)] = \\\n",
    "        raw0[\"{}_exp_receipt\".format(x)] / raw0[\"{}_exp_wk\".format(x)]\n",
    "        \n",
    "        # Filling in the single missing value for Date_diff\n",
    "        raw0['Date_diff'].fillna(0,inplace=True)\n",
    "        \n",
    "    # Filling in missing values from the check above\n",
    "    fill_na_list = ['Bread_wk_perc','Bread_exp_receipt','Bread_exp_wk',\n",
    "                 'Bread_wk_exp_perc','Cooked_meats_receipt','Cooked_meats_wk','Cooked_meats_wk_perc','Cooked_meats_exp_receipt',\n",
    "                 'Cooked_meats_exp_wk','Raw_meats_receipt','Raw_meats_wk','Raw_meats_wk_perc','Raw_meats_exp_receipt',\n",
    "                 'Raw_meats_exp_wk','Raw_meats_wk_exp_perc','Eating_out_receipt','Eating_out_wk','Eating_out_wk_perc',\n",
    "                 'Eating_out_exp_receipt','Eating_out_exp_wk','Eating_out_wk_exp_perc','Snacks_receipt','Snacks_wk',\n",
    "                 'Snacks_wk_perc','Snacks_exp_receipt','Snacks_exp_wk','Snacks_wk_exp_perc','Drinks_receipt','Drinks_wk',\n",
    "                 'Drinks_wk_perc','Drinks_exp_receipt','Drinks_exp_wk','Drinks_wk_exp_perc','Vegetables_receipt',\n",
    "                 'Vegetables_wk','Vegetables_wk_perc','Vegetables_exp_receipt','Vegetables_exp_wk','Vegetables_wk_exp_perc',\n",
    "                 'Fruit_receipt','Fruit_wk','Fruit_wk_perc','Fruit_exp_receipt','Fruit_exp_wk','Fruit_wk_exp_perc',\n",
    "                 'Cooking_base_receipt','Cooking_base_wk','Cooking_base_wk_perc','Cooking_base_exp_receipt','Cooking_base_exp_wk',\n",
    "                 'Cooking_base_wk_exp_perc','Dairy_produce_receipt','Dairy_produce_wk','Dairy_produce_wk_perc',\n",
    "                 'Dairy_produce_exp_receipt','Dairy_produce_exp_wk','Dairy_produce_wk_exp_perc','Seasoning_receipt',\n",
    "                 'Seasoning_wk','Seasoning_wk_perc','Seasoning_exp_receipt','Seasoning_exp_wk','Seasoning_wk_exp_perc',\n",
    "                 'Breakfast_receipt','Breakfast_wk','Breakfast_wk_perc','Breakfast_exp_receipt','Breakfast_exp_wk',\n",
    "                 'Breakfast_wk_exp_perc','Transport_wk','Transport_wk_perc','Transport_exp_receipt','Transport_exp_wk',\n",
    "                 'Transport_wk_exp_perc','DIY_receipt','DIY_wk','DIY_wk_perc','DIY_exp_receipt','DIY_exp_wk','DIY_wk_exp_perc',\n",
    "                 'Electronics_receipt','Electronics_wk','Electronics_wk_perc','Electronics_exp_receipt','Electronics_exp_wk',\n",
    "                 'Electronics_wk_exp_perc','Education_receipt','Education_wk','Education_wk_perc','Education_exp_receipt',\n",
    "                 'Education_exp_wk','Education_wk_exp_perc','Tech_and_services_receipt','Tech_and_services_wk',\n",
    "                 'Tech_and_services_wk_perc','Tech_and_services_exp_receipt','Tech_and_services_exp_wk',\n",
    "                 'Tech_and_services_wk_exp_perc','Cosmetics_and_selfcare_receipt','Cosmetics_and_selfcare_wk',\n",
    "                 'Cosmetics_and_selfcare_wk_perc','Cosmetics_and_selfcare_exp_receipt','Cosmetics_and_selfcare_exp_wk',\n",
    "                 'Cosmetics_and_selfcare_wk_exp_perc','Clothes_and_shoes_receipt','Clothes_and_shoes_wk',\n",
    "                 'Clothes_and_shoes_wk_perc','Clothes_and_shoes_exp_receipt','Clothes_and_shoes_exp_wk',\n",
    "                 'Clothes_and_shoes_wk_exp_perc','House_and_kitchen_receipt','House_and_kitchen_wk',\n",
    "                 'House_and_kitchen_wk_perc','House_and_kitchen_exp_receipt','House_and_kitchen_exp_wk',\n",
    "                 'House_and_kitchen_wk_exp_perc']\n",
    "\n",
    "    for x in fill_na_list:\n",
    "        y = raw0.groupby(['Receipt_id'])[x].transform('sum')\n",
    "        raw0[x]= raw0.groupby(['Receipt_id'])[x].apply(lambda x: x.fillna(y))\n",
    "\n",
    "    # Encoding Part_of_day\n",
    "    raw0['Part_of_day_num'] = raw0['Part_of_day']\n",
    "\n",
    "\n",
    "    encode_Part_of_day = {'Part_of_day_num':{'Early':0,\n",
    "                                             'Morning':1,\n",
    "                                             'Afternoon':2,\n",
    "                                             'Evening':3,\n",
    "                                             'Late_night':4}}\n",
    "\n",
    "    # Applying the encoder\n",
    "    raw0.replace(encode_Part_of_day, inplace=True)\n",
    "\n",
    "    # Encode Payment_Type\n",
    "    raw0['Payment_Type_num'] = raw0['Payment_Type']\n",
    "\n",
    "    encode_Payment_Type = {'Payment_Type_num': {'Card':0,'Cash':1,'Plan':2}}\n",
    "\n",
    "    # applying the encoder\n",
    "    raw0.replace(encode_Payment_Type, inplace=True)\n",
    "\n",
    "    # Encoding Card_Source\n",
    "    raw0['Card_Source_num'] = raw0['Card_Source']\n",
    "\n",
    "    encode_Card_Source = {'Card_Source_num': {'Contactless':0,\n",
    "                                              'Pin':1,\n",
    "                                              '0':2,\n",
    "                                              'DD':3,\n",
    "                                              'DB':4,\n",
    "                                              'Plan':5,'Transfer':6}}\n",
    "\n",
    "    # Applying the encoder\n",
    "    raw0.replace(encode_Card_Source, inplace=True)\n",
    "    \n",
    "    raw0=raw0.query(\"Receipt_id == {}\".format(Receipt_id_g))\n",
    "\n",
    "    raw1 = raw0[['Receipt_id','Venue_id','Total_Nbr_of_Items','Total_Price','Date_diff','Week_day_numeric','Nbr_trips_per_wk','Nbr_items_per_wk',\n",
    "         'Nbr_items_wk_perc','Expenditure_per_wk','Total_Exp_wk_perc','hour','Part_of_day_num',\n",
    "         'Payment_Type_num','Card_Source_num','Bread_receipt','Bread_wk','Bread_wk_perc',\n",
    "         'Bread_exp_receipt','Bread_exp_wk','Bread_wk_exp_perc','Cooked_meats_receipt','Cooked_meats_wk','Cooked_meats_wk_perc',\n",
    "         'Cooked_meats_exp_receipt','Cooked_meats_exp_wk','Raw_meats_receipt','Raw_meats_wk','Raw_meats_wk_perc','Raw_meats_exp_receipt',\n",
    "         'Raw_meats_exp_wk','Raw_meats_wk_exp_perc','Eating_out_receipt','Eating_out_wk','Eating_out_wk_perc','Eating_out_exp_receipt',\n",
    "         'Eating_out_exp_wk','Eating_out_wk_exp_perc','Snacks_receipt','Snacks_wk','Snacks_wk_perc','Snacks_exp_receipt','Snacks_exp_wk',\n",
    "         'Snacks_wk_exp_perc','Drinks_receipt','Drinks_wk','Drinks_wk_perc','Drinks_exp_receipt','Drinks_exp_wk','Drinks_wk_exp_perc',\n",
    "         'Vegetables_receipt','Vegetables_wk','Vegetables_wk_perc','Vegetables_exp_receipt','Vegetables_exp_wk',\n",
    "         'Vegetables_wk_exp_perc','Fruit_receipt','Fruit_wk','Fruit_wk_perc','Fruit_exp_receipt','Fruit_exp_wk','Fruit_wk_exp_perc',\n",
    "         'Cooking_base_receipt','Cooking_base_wk','Cooking_base_wk_perc','Cooking_base_exp_receipt','Cooking_base_exp_wk',\n",
    "         'Cooking_base_wk_exp_perc','Dairy_produce_receipt','Dairy_produce_wk','Dairy_produce_wk_perc',\n",
    "         'Dairy_produce_exp_receipt','Dairy_produce_exp_wk','Dairy_produce_wk_exp_perc','Seasoning_receipt',\n",
    "         'Seasoning_wk','Seasoning_wk_perc','Seasoning_exp_receipt','Seasoning_exp_wk','Seasoning_wk_exp_perc',\n",
    "         'Breakfast_receipt','Breakfast_wk','Breakfast_wk_perc','Breakfast_exp_receipt','Breakfast_exp_wk',\n",
    "         'Breakfast_wk_exp_perc','Transport_wk','Transport_wk_perc','Transport_exp_receipt','Transport_exp_wk',\n",
    "         'Transport_wk_exp_perc','DIY_receipt','DIY_wk','DIY_wk_perc','DIY_exp_receipt','DIY_exp_wk','DIY_wk_exp_perc',\n",
    "         'Electronics_receipt','Electronics_wk','Electronics_wk_perc','Electronics_exp_receipt','Electronics_exp_wk',\n",
    "         'Electronics_wk_exp_perc','Education_receipt','Education_wk','Education_wk_perc','Education_exp_receipt',\n",
    "         'Education_exp_wk','Education_wk_exp_perc','Tech_and_services_receipt','Tech_and_services_wk',\n",
    "         'Tech_and_services_wk_perc','Tech_and_services_exp_receipt','Tech_and_services_exp_wk',\n",
    "         'Tech_and_services_wk_exp_perc','Cosmetics_and_selfcare_receipt','Cosmetics_and_selfcare_wk',\n",
    "         'Cosmetics_and_selfcare_wk_perc','Cosmetics_and_selfcare_exp_receipt','Cosmetics_and_selfcare_exp_wk',\n",
    "         'Cosmetics_and_selfcare_wk_exp_perc','Clothes_and_shoes_receipt','Clothes_and_shoes_wk',\n",
    "         'Clothes_and_shoes_wk_perc','Clothes_and_shoes_exp_receipt','Clothes_and_shoes_exp_wk',\n",
    "         'Clothes_and_shoes_wk_exp_perc','House_and_kitchen_receipt','House_and_kitchen_wk',\n",
    "         'House_and_kitchen_wk_perc','House_and_kitchen_exp_receipt','House_and_kitchen_exp_wk',\n",
    "         'House_and_kitchen_wk_exp_perc']].drop_duplicates(subset=['Receipt_id'])\n",
    "\n",
    "    # Droping Receipt_id\n",
    "    raw1.drop(['Receipt_id'], axis=1, inplace=True)\n",
    "\n",
    "    # capping outliers for Total_Nbr_of_Items at the 99th quantile\n",
    "    #raw1['Total_Nbr_of_Items'].clip(upper=raw1['Total_Nbr_of_Items'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for Total_Price at the 95th quantile (a value of 35.2)\n",
    "    # this is more reasonable than the 99th quantile\n",
    "    raw1['Total_Price'].clip(upper=raw1['Total_Price'].quantile(.95), inplace=True)\n",
    "\n",
    "    # capping outliers for Nbr_trips_per_wk at the 95th quantile \n",
    "    raw1['Nbr_trips_per_wk'].clip(upper=raw1['Nbr_trips_per_wk'].quantile(.95), inplace=True)\n",
    "\n",
    "    # capping outliers for Nbr_items_per_wk at the 95th quantile \n",
    "    raw1['Nbr_items_per_wk'].clip(upper=raw1['Nbr_items_per_wk'].quantile(.95), inplace=True)\n",
    "\n",
    "    # capping outliers for Expenditure_per_wk at the 95th quantile \n",
    "    raw1['Expenditure_per_wk'].clip(upper=raw1['Expenditure_per_wk'].quantile(.95), inplace=True)\n",
    "\n",
    "    # capping outliers for Electronics_exp_receipt at the 99th quantile \n",
    "    raw1['Electronics_exp_receipt'].clip(upper=raw1['Electronics_exp_receipt'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for Electronics_exp_wk at the 99th quantile \n",
    "    raw1['Electronics_exp_wk'].clip(upper=raw1['Electronics_exp_wk'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for Education_exp_receipt at the 99th quantile \n",
    "    raw1['Education_exp_receipt'].clip(upper=raw1['Education_exp_receipt'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for Education_exp_wk at the 99th quantile \n",
    "    raw1['Education_exp_wk'].clip(upper=raw1['Education_exp_wk'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for DIY_exp_receipt at the 99th quantile \n",
    "    raw1['DIY_exp_receipt'].clip(upper=raw1['DIY_exp_receipt'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for DIY_exp_wk at the 99th quantile \n",
    "    raw1['DIY_exp_wk'].clip(upper=raw1['DIY_exp_wk'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for Cosmetics_and_selfcare_exp_receipt at the 99th quantile \n",
    "    raw1['Cosmetics_and_selfcare_exp_receipt'].clip(upper=raw1['Cosmetics_and_selfcare_exp_receipt'].quantile(.99), inplace=True)\n",
    "\n",
    "    # capping outliers for Cosmetics_and_selfcare_exp_wk at the 99th quantile \n",
    "    raw1['Cosmetics_and_selfcare_exp_wk'].clip(upper=raw1['Cosmetics_and_selfcare_exp_wk'].quantile(.99), inplace=True)\n",
    "    \n",
    "    return raw1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32ae8a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For standard scaler fit transform \n",
    "# use the saved version of standard scaler\n",
    "# load it with joblib\n",
    "def predict(raw1):\n",
    "    scaler = joblib.load('./Models/StandardScaler_06102022')\n",
    "    X_transform = scaler.transform(raw1)\n",
    "    X_transform = pd.DataFrame(X_transform, columns=raw1.columns)\n",
    "\n",
    "        # predict using the classifier  model\n",
    "    rfc_loaded = joblib.load('./Models/RandomForestClassifier_Model_27092022')\n",
    "    Rfc_Guest_pred = rfc_loaded.predict(X_transform)\n",
    "\n",
    "    # droping Total_Price as it is the target feature for the regressor model\n",
    "    X_transform.drop(['Total_Price'],axis=1, inplace=True)\n",
    "\n",
    "    # predict using the regressor model\n",
    "    RFR_loaded = joblib.load('./Models/RandomForestRegressor_Model_06102022')\n",
    "    RFR_Guest_exp_pred = RFR_loaded.predict(X_transform)\n",
    "\n",
    "    # inverse transforming Total_Price estimate\n",
    "    # the manual inverse_transform is done because\n",
    "    # StandardScaler was outputing errors that have yet to be resolved\n",
    "    # in the interest of time, I opted for this:\n",
    "    mean = scaler.mean_[2]\n",
    "    std = np.sqrt(scaler.var_[2])\n",
    "    estimate_total_price = (RFR_Guest_exp_pred * std) + mean\n",
    "    \n",
    "    Models_Output = [\n",
    "                    Rfc_Guest_pred,\n",
    "                     RFR_Guest_exp_pred,\n",
    "                     estimate_total_price\n",
    "                    ]\n",
    "    \n",
    "    return Models_Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd7ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5992/2474274061.py:430: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  raw0['Part_of_day_num'] = raw0['Part_of_day']\n"
     ]
    }
   ],
   "source": [
    "raw1 = transform_data(Venue_id_g,Total_Nbr_of_Items_g,Total_Price_g,\n",
    "            Receipt_Date_g,Receipt_Time_g,Payment_Type_g,\n",
    "            Card_Source_g,Item_name_g,Item_Price_g\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1211fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models_Output = predict(raw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14fa5763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1]), array([0.48155385]), array([15.06296413])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output is [RFC output], [RFRegressor standardized output], [RFRegressor reverse transform output]\n",
    "Models_Output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
